@inproceedings{anconaRPythonStepReconciling2007,
  title = {{{RPython}}: {{A Step Towards Reconciling Dynamically}} and {{Statically Typed OO Languages}}},
  shorttitle = {{{RPython}}},
  booktitle = {Proceedings of the 2007 {{Symposium}} on {{Dynamic Languages}}},
  author = {Ancona, Davide and Ancona, Massimo and Cuni, Antonio and Matsakis, Nicholas D.},
  year = {2007},
  series = {{{DLS}} '07},
  pages = {53--64},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1297081.1297091},
  urldate = {2019-11-12},
  abstract = {Although the C-based interpreter of Python is reasonably fast, implementations on the CLI or the JVM platforms offers some advantages in terms of robustness and interoperability. Unfortunately, because the CLI and JVM are primarily designed to execute statically typed, object-oriented languages, most dynamic language implementations cannot use the native bytecodes for common operations like method calls and exception handling; as a result, they are not able to take full advantage of the power offered by the CLI and JVM. We describe a different approach that attempts to preserve the flexibility of Python, while still allowing for efficient execution. This is achieved by limiting the use of the more dynamic features of Python to an initial, bootstrapping phase. This phase is used to construct a final RPython (Restricted Python) program that is actually executed. RPython is a proper subset of Python, is statically typed, and does not allow dynamic modification of class or method definitions; however, it can still take advantage of Python features such as mixins and first-class methods and classes. This paper presents an overview of RPython, including its design and its translation to both CLI and JVM bytecode. We show how the bootstrapping phase can be used to implement advanced features, like extensible classes and generative programming. We also discuss what work remains before RPython is truly ready for general use, and compare the performance of RPython with that of other approaches.},
  isbn = {978-1-59593-868-8},
  keywords = {.NET,JVM,Python},
  file = {C:\Users\caner\Zotero\storage\MVZCMYBI\Ancona et al. - 2007 - RPython A Step Towards Reconciling Dynamically an.pdf}
}

@article{bolzMetatracingMakesFast,
  title = {Meta-Tracing Makes a Fast {{Racket}}},
  author = {Bolz, Carl Friedrich and Pape, Tobias and Siek, Jeremy and {Tobin-Hochstadt}, Sam},
  pages = {7},
  abstract = {Tracing just-in-time (JIT) compilers record and optimize the instruction sequences they observe at runtime. With some modifications, a tracing JIT can perform well even when the executed program is itself an interpreter, an approach called meta-tracing. The advantage of meta-tracing is that it separates the concern of JIT compilation from language implementation, enabling the same JIT compiler to be used with many different languages. The RPython meta-tracing JIT compiler has enabled the efficient interpretation of several dynamic languages including Python (PyPy), Prolog, and Smalltalk. In this paper we present initial findings in applying the RPython JIT to Racket. Racket comes from the Scheme family of programming languages for which there are mature static optimizing compilers. We present the result of spending just a couple person-months implementing and tuning an implementation of Racket written in RPython. The results are promising, with a geometric mean equal to Racket's performance and within a factor of 2 slower than Gambit and Larceny on a collection of standard Scheme benchmarks. The results on individual benchmarks vary widely. On the positive side, our interpreter is sometimes up to two to six times faster than Gambit, an order of magnitude faster than Larceny, and two orders of magnitude faster than the Racket JIT compiler when making heavy use of continuations. On the negative side, our interpreter is sometimes three times slower than Racket, nine times slower than Gambit, and five times slower than Larceny.},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\2RGFN3VC\Bolz et al. - Meta-tracing makes a fast Racket.pdf}
}

@inproceedings{hotpath:06,
  title = {{{HotpathVM}}: {{An Effective JIT Compiler}} for {{Resource-constrained Devices}}},
  shorttitle = {{{HotpathVM}}},
  booktitle = {Proceedings of the {{2Nd International Conference}} on {{Virtual Execution Environments}}},
  author = {Gal, Andreas and Probst, Christian W. and Franz, Michael},
  year = {2006},
  series = {{{VEE}} '06},
  pages = {144--153},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1134760.1134780},
  urldate = {2019-11-16},
  abstract = {We present a just-in-time compiler for a Java VM that is small enough to fit on resource-constrained devices, yet is surprisingly effective. Our system dynamically identifies traces of frequently executed bytecode instructions (which may span several basic blocks across several methods) and compiles them via Static Single Assignment (SSA) construction. Our novel use of SSA form in this context allows to hoist instructions across trace side-exits without necessitating expensive compensation code in off-trace paths. The overall memory consumption (code and data) of our system is only 150 kBytes, yet benchmarks show a speedup that in some cases rivals heavy-weight just-in-time compilers.},
  isbn = {978-1-59593-332-4},
  keywords = {dynamic compilation,embedded and resource-constrained systems,mixed-mode interpretive compiled systems,software trace scheduling,static single assignment form,virtual machines},
  file = {C:\Users\caner\Zotero\storage\MUT26PBM\Gal et al. - 2006 - HotpathVM An Effective JIT Compiler for Resource-.pdf}
}

@inproceedings{izawaAmalgamatingDifferentJIT2020,
  title = {Amalgamating {{Different JIT Compilations}} in a {{Meta-tracing JIT Compiler Framework}}},
  booktitle = {Proceedings of the 16th {{ACM SIGPLAN International Symposium}} on {{Dynamic Languages}}},
  author = {Izawa, Yusuke and Masuhara, Hidehiko},
  year = {2020},
  month = nov,
  eprint = {2011.03516},
  primaryclass = {cs},
  pages = {1--15},
  doi = {10.1145/3426422.3426977},
  urldate = {2025-05-28},
  abstract = {Many modern virtual machines, such as JVMs, .NET Framework, and V8, employ a just-in-time (JIT) compiler to achieve their high-performance. There are two major compilation strategies; trace-based compilation and method-based compilation. They have their own advantages and disadvantages, so we presume that applying suitable strategies for different program parts is essential for faster execution. This paper proposes a new approach called the meta-hybrid JIT compiler framework, which combined the two strategies in a single meta-JIT compiler framework. We implemented the BacCaml framework for proof-of-concept. We also report that some programs actually ran faster by the hybrid compilation in our experiments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Programming Languages},
  file = {C\:\\Users\\caner\\Zotero\\storage\\4NSDVM5Y\\Izawa and Masuhara - 2020 - Amalgamating Different JIT Compilations in a Meta-tracing JIT Compiler Framework.pdf;C\:\\Users\\caner\\Zotero\\storage\\XCC3HBTP\\2011.html}
}

@misc{izawaLightweightMethodGenerating2025,
  title = {A {{Lightweight Method}} for {{Generating Multi-Tier JIT Compilation Virtual Machine}} in a {{Meta-Tracing Compiler Framework}}},
  author = {Izawa, Yusuke and Masuhara, Hidehiko and {Bolz-Tereick}, Carl Friedrich},
  year = {2025},
  month = apr,
  number = {arXiv:2504.17460},
  eprint = {2504.17460},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.17460},
  urldate = {2025-05-28},
  abstract = {Meta-compiler frameworks, such as RPython and Graal/Truffle, generate high-performance virtual machines (VMs) from interpreter definitions. Although they generate VMs with high-quality just-in-time (JIT) compilers, they still lack an important feature that dedicated VMs (i.e., VMs that are developed for specific languages) have, namely {\textbackslash}emph\{multi-tier compilation\}. Multi-tier compilation uses light-weight compilers at early stages and highly-optimizing compilers at later stages in order to balance between compilation overheads and code quality. We propose a novel approach to enabling multi-tier compilation in the VMs generated by a meta-compiler framework. Instead of extending the JIT compiler backend of the framework, our approach drives an existing (heavyweight) compiler backend in the framework to quickly generate unoptimized native code by merely embedding directives and compile-time operations into interpreter definitions. As a validation of the approach, we developed 2SOM, a Simple Object Machine with a two-tier JIT compiler based on RPython. 2SOM first applies the tier-1 threaded code generator that is generated by our proposed technique, then, to the loops that exceed a threshold, applies the tier-2 tracing JIT compiler that is generated by the original RPython framework. Our performance evaluation that runs a program with a realistic workload showed that 2SOM improved, when compared against an RPython-based VM, warm-up performance by 15{\textbackslash}\%, with merely a 5{\textbackslash}\% reduction in peak performance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Programming Languages},
  file = {C\:\\Users\\caner\\Zotero\\storage\\SX29ZQUE\\Izawa et al. - 2025 - A Lightweight Method for Generating Multi-Tier JIT Compilation Virtual Machine in a Meta-Tracing Com.pdf;C\:\\Users\\caner\\Zotero\\storage\\7WFHXFWI\\2504.html}
}

@inproceedings{loop-aware:12,
  title = {Loop-Aware {{Optimizations}} in {{PyPy}}'s {{Tracing JIT}}},
  booktitle = {Proceedings of the 8th {{Symposium}} on {{Dynamic Languages}}},
  author = {akan Ard{\"o}, H{\textbackslash}a and Bolz, Carl Friedrich and FijaBkowski, Maciej},
  year = {2012},
  series = {{{DLS}} '12},
  pages = {63--72},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/2384577.2384586},
  urldate = {2019-03-22},
  abstract = {One of the nice properties of a tracing just-in-time compiler (JIT) is that many of its optimizations are simple, requiring one forward pass only. This is not true for loop-invariant code motion which is a very important optimization for code with tight kernels. Especially for dynamic languages that typically perform quite a lot of loop invariant type checking, boxed value unwrapping and virtual method lookups. In this paper we explain a scheme pioneered within the context of the LuaJIT project for making basic optimizations loop-aware by using a simple pre-processing step on the trace without changing the optimizations themselves. We have implemented the scheme in RPython's tracing JIT compiler. PyPy's Python JIT executing simple numerical kernels can become up to two times faster, bringing the performance into the ballpark of static language compilers.},
  isbn = {978-1-4503-1564-7},
  keywords = {loop-invariant code motion,optimization,tracing JIT},
  file = {C:\Users\caner\Zotero\storage\QSMR5HNR\Ardö et al. - 2012 - Loop-aware Optimizations in PyPy's Tracing JIT.pdf}
}

@inproceedings{malloc-removal:11,
  title = {Allocation {{Removal}} by {{Partial Evaluation}} in a {{Tracing JIT}}},
  booktitle = {Proceedings of the 20th {{ACM SIGPLAN Workshop}} on {{Partial Evaluation}} and {{Program Manipulation}}},
  author = {Bolz, Carl Friedrich and Cuni, Antonio and FijaBkowski, Maciej and Leuschel, Michael and Pedroni, Samuele and Rigo, Armin},
  year = {2011},
  series = {{{PEPM}} '11},
  pages = {43--52},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1929501.1929508},
  urldate = {2019-11-16},
  abstract = {The performance of many dynamic language implementations suffers from high allocation rates and runtime type checks. This makes dynamic languages less applicable to purely algorithmic problems, despite their growing popularity. In this paper we present a simple compiler optimization based on online partial evaluation to remove object allocations and runtime type checks in the context of a tracing JIT. We evaluate the optimization using a Python VM and find that it gives good results for all our (real-life) benchmarks.},
  isbn = {978-1-4503-0485-6},
  keywords = {optimization,partial evaluation,tracing jit},
  file = {C:\Users\caner\Zotero\storage\7GRXDUIE\Bolz et al. - 2011 - Allocation Removal by Partial Evaluation in a Trac.pdf}
}

@inproceedings{pycketmain,
  title = {Pycket: {{A Tracing JIT}} for a {{Functional Language}}},
  shorttitle = {Pycket},
  booktitle = {Proceedings of the 20th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  author = {Bauman, Spenser and Bolz, Carl Friedrich and Hirschfeld, Robert and Kirilichev, Vasily and Pape, Tobias and Siek, Jeremy G. and {Tobin-Hochstadt}, Sam},
  year = {2015},
  series = {{{ICFP}} 2015},
  pages = {22--34},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/2784731.2784740},
  urldate = {2019-03-22},
  abstract = {We present Pycket, a high-performance tracing JIT compiler for Racket. Pycket supports a wide variety of the sophisticated features in Racket such as contracts, continuations, classes, structures, dynamic binding, and more. On average, over a standard suite of benchmarks, Pycket outperforms existing compilers, both Racket's JIT and other highly-optimizing Scheme compilers. Further, Pycket provides much better performance for Racket proxies than existing systems, dramatically reducing the overhead of contracts and gradual typing. We validate this claim with performance evaluation on multiple existing benchmark suites. The Pycket implementation is of independent interest as an application of the RPython meta-tracing framework (originally created for PyPy), which automatically generates tracing JIT compilers from interpreters. Prior work on meta-tracing focuses on bytecode interpreters, whereas Pycket is a high-level interpreter based on the CEK abstract machine and operates directly on abstract syntax trees. Pycket supports proper tail calls and first-class continuations. In the setting of a functional language, where recursion and higher-order functions are more prevalent than explicit loops, the most significant performance challenge for a tracing JIT is identifying which control flows constitute a loop---we discuss two strategies for identifying loops and measure their impact.},
  isbn = {978-1-4503-3669-7},
  keywords = {contracts,functional languages,JIT compilers,Racket,tracing},
  file = {C:\Users\caner\Zotero\storage\2JP3BUTY\Bauman et al. - 2015 - Pycket A Tracing JIT for a Functional Language.pdf}
}

@article{pycketmain2,
  title = {Sound Gradual Typing: Only Mostly Dead},
  shorttitle = {Sound Gradual Typing},
  author = {Bauman, Spenser and {Bolz-Tereick}, Carl Friedrich and Siek, Jeremy and {Tobin-Hochstadt}, Sam},
  year = {2017},
  month = oct,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {1},
  number = {OOPSLA},
  pages = {1--24},
  issn = {24751421},
  doi = {10.1145/3133878},
  urldate = {2019-11-10},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\DSSSEG9Z\Bauman et al. - 2017 - Sound gradual typing only mostly dead.pdf}
}

@inproceedings{pypy-main,
  title = {Tracing the {{Meta-level}}: {{PyPy}}'s {{Tracing JIT Compiler}}},
  shorttitle = {Tracing the {{Meta-level}}},
  booktitle = {Proceedings of the 4th {{Workshop}} on the {{Implementation}}, {{Compilation}}, {{Optimization}} of {{Object-Oriented Languages}} and {{Programming Systems}}},
  author = {Bolz, Carl Friedrich and Cuni, Antonio and Fijalkowski, Maciej and Rigo, Armin},
  year = {2009},
  series = {{{ICOOOLPS}} '09},
  pages = {18--25},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1565824.1565827},
  urldate = {2019-03-22},
  abstract = {We attempt to apply the technique of Tracing JIT Compilers in the context of the PyPy project, i.e., to programs that are interpreters for some dynamic languages, including Python. Tracing JIT compilers can greatly speed up programs that spend most of their time in loops in which they take similar code paths. However, applying an unmodified tracing JIT to a program that is itself a bytecode interpreter results in very limited or no speedup. In this paper we show how to guide tracing JIT compilers to greatly improve the speed of bytecode interpreters. One crucial point is to unroll the bytecode dispatch loop, based on two kinds of hints provided by the implementer of the bytecode interpreter. We evaluate our technique by applying it to two PyPy interpreters: one is a small example, and the other one is the full Python interpreter.},
  isbn = {978-1-60558-541-3},
  file = {C:\Users\caner\Zotero\storage\ZW64A5W8\Bolz et al. - 2009 - Tracing the Meta-level PyPy's Tracing JIT Compile.pdf}
}
