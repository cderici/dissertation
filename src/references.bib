@book{appelCompilingContinuations2007,
  title = {Compiling with {{Continuations}}},
  author = {Appel, Andrew W.},
  year = {2007},
  month = jan,
  publisher = {Cambridge University Press},
  address = {USA},
  abstract = {This book shows how continuation-passing style is used as an intermediate representation to perform optimizations and program transformations. Continuations can be used to compile most programming languages. The method is illustrated in a compiler for the programming language Standard ML. Prior knowledge of ML, however, is not necessary, as the author carefully explains each concept as it arises. This is the first book to show how concepts from the theory of programming languages can be applied to the production of practical optimizing compilers for modern languages like ML. All the details of compiling are covered, including the interface to a runtime system and garbage collector.},
  isbn = {978-0-521-03311-4}
}

@article{bolzMetatracingMakesFast2014,
  title = {Meta-Tracing Makes a Fast {{Racket}}},
  author = {Bolz, Carl Friedrich and Pape, Tobias and Siek, Jeremy and {Tobin-Hochstadt}, Sam},
  year = {2014},
  pages = {7},
  abstract = {Tracing just-in-time (JIT) compilers record and optimize the instruction sequences they observe at runtime. With some modifications, a tracing JIT can perform well even when the executed program is itself an interpreter, an approach called meta-tracing. The advantage of meta-tracing is that it separates the concern of JIT compilation from language implementation, enabling the same JIT compiler to be used with many different languages. The RPython meta-tracing JIT compiler has enabled the efficient interpretation of several dynamic languages including Python (PyPy), Prolog, and Smalltalk. In this paper we present initial findings in applying the RPython JIT to Racket. Racket comes from the Scheme family of programming languages for which there are mature static optimizing compilers. We present the result of spending just a couple person-months implementing and tuning an implementation of Racket written in RPython. The results are promising, with a geometric mean equal to Racket's performance and within a factor of 2 slower than Gambit and Larceny on a collection of standard Scheme benchmarks. The results on individual benchmarks vary widely. On the positive side, our interpreter is sometimes up to two to six times faster than Gambit, an order of magnitude faster than Larceny, and two orders of magnitude faster than the Racket JIT compiler when making heavy use of continuations. On the negative side, our interpreter is sometimes three times slower than Racket, nine times slower than Gambit, and five times slower than Larceny.},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\2RGFN3VC\Bolz et al. - Meta-tracing makes a fast Racket.pdf}
}

@article{bolzPhDThesis,
  title = {{Meta-Tracing Just-in-Time Compilation for RPython}},
  author = {Bolz, Carl Friedrich},
  langid = {ngerman},
  file = {C:\Users\caner\Zotero\storage\57J8CJLC\Bolz - Meta-Tracing Just-in-Time Compilation for RPython.pdf}
}

@inproceedings{danvy:93,
  title = {Separating Stages in the Continuation-Passing Style Transformation},
  booktitle = {Proceedings of the 20th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages},
  author = {Lawall, Julia L. and Danvy, Olivier},
  year = {1993},
  month = mar,
  series = {{{POPL}} '93},
  pages = {124--136},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/158511.158613},
  urldate = {2025-06-23},
  abstract = {The continuation-passing style (CPS) transformation is powerful but complex. Our thesis is that this transformation is in fact compound, and we set out to stage it. We factor the CPS transformation into several steps, separating aspects in each step: (1) Intermediate values are named; (2) Continuations are introduced; (3) Sequencing order is decided and administrative reductions are performed.Step 1 determines the evaluation order (e.g., call-by-name or call-by-value). Step 2 isolates the introduction of continuations and is expressed with local, structure-preserving rewrite rules --- a novel aspect standing in sharp contrast with the usual CPS transformations. Step 3 determines the ordering of continuations (e.g., left-to-right or right-to-left evaluation) and leads to the familiar-looking continuation-passing terms.Step 2 is completely reversible and Steps 1 and 3 form Galois connections. Together they lead to the direct style (DS) transformation of our earlier work (including first-class continuations): (1) Intermediate continuations are named and sequencing order is abstracted; (2) Second-class continuations are eliminated; (3) Administrative reductions are performed.A subset of these transformations can leverage program manipulation systems: CPS-based compilers can modify sequencing to improve e.g., register allocation; static program analyzers can yield more precise results; and overspecified CPS programs can be rescheduled. Separating aspects of the CPS transformation also enables a new programming style, with applications to nondeterministic programming. As a byproduct, our work also suggests a new continuation semantics for unspecified sequencing orders in programming languages (e.g., Scheme).},
  isbn = {978-0-89791-560-1},
  file = {C:\Users\caner\Zotero\storage\5LRL7IK2\Lawall and Danvy - 1993 - Separating stages in the continuation-passing style transformation.pdf}
}

@article{dynamo,
  title = {Dynamo: {{A Transparent Dynamic Optimization System}}},
  author = {Bala, Vasanth and Duesterwald, Evelyn and Banerjia, Sanjeev},
  pages = {12},
  abstract = {We describe the design and implementation of Dynamo, a software dynamic optimization system that is capable of transparently improving the performance of a native instruction stream as it executes on the processor. The input native instruction stream to Dynamo can be dynamically generated (by a JIT for example), or it can come from the execution of a statically compiled native binary. This paper evaluates the Dynamo system in the latter, more challenging situation, in order to emphasize the limits, rather than the potential, of the system. Our experiments demonstrate that even statically optimized native binaries can be accelerated Dynamo, and often by a significant degree. For example, the average performance of --O optimized SpecInt95 benchmark binaries created by the HP product C compiler is improved to a level comparable to their --O4 optimized version running without Dynamo. Dynamo achieves this by focusing its efforts on optimization opportunities that tend to manifest only at runtime, and hence opportunities that might be difficult for a static compiler to exploit. Dynamo's operation is transparent in the sense that it does not depend on any user annotations or binary instrumentation, and does not require multiple runs, or any special compiler, operating system or hardware support. The Dynamo prototype presented here is a realistic implementation running on an HP PA-8000 workstation under the HPUX 10.20 operating system.},
  langid = {english}
}

@inproceedings{felleisen87,
  title = {Control Operators, the {{SECD-machine}}, and the {$\lambda$}-Calculus},
  booktitle = {Formal {{Description}} of {{Programming Concepts}}},
  author = {Felleisen, Matthias and Friedman, Daniel P.},
  year = {1987},
  keywords = {Lambda calculus,SECD machine}
}

@misc{findler-felleisen:2002,
  title = {Contracts for Higher-Order Functions {\textbar} {{Proceedings}} of the Seventh {{ACM SIGPLAN}} International Conference on {{Functional}} Programming},
  urldate = {2025-06-23},
  howpublished = {https://dl-acm-org.proxyiub.uits.iu.edu/doi/10.1145/581478.581484},
  file = {C:\Users\caner\Zotero\storage\DJUW4VN7\581478.html}
}

@article{flanagan:93,
  title = {The Essence of Compiling with Continuations},
  author = {Flanagan, Cormac and Sabry, Amr and Duba, Bruce F. and Felleisen, Matthias},
  year = {1993},
  month = jun,
  journal = {SIGPLAN Not.},
  volume = {28},
  number = {6},
  pages = {237--247},
  issn = {0362-1340},
  doi = {10.1145/173262.155113},
  urldate = {2025-06-23},
  abstract = {In order to simplify the compilation process, many compilers for higher-order languages use the continuation-passing style (CPS) transformation in a first phase to generate an intermediate representation of the source program. The salient aspect of this intermediate form is that all procedures take an argument that represents the rest of the computation (the ``continuation''). Since the nai{\textasciidieresis}ve CPS transformation considerably increases the size of programs, CPS compilers perform reductions to produce a more compact intermediate representation. Although often implemented as a part of the CPS transformation, this step is conceptually a second phase. Finally, code generators for typical CPS compilers treat continuations specially in order to optimize the interpretation of continuation parameters.A thorough analysis of the abstract machine for CPS terms show that the actions of the code generator invert the nai{\textasciidieresis}ve CPS translation step. Put differently, the combined effect of the three phases is equivalent to a source-to-source transformation that simulates the compaction phase. Thus, fully developed CPS compilers do not need to employ the CPS transformation but can achieve the same results with a simple source-level transformation.},
  file = {C:\Users\caner\Zotero\storage\VWHIVX6I\Flanagan et al. - 1993 - The essence of compiling with continuations.pdf}
}

@article{flatt:2002,
  title = {Composable and Compilable Macros: You Want It When?},
  shorttitle = {Composable and Compilable Macros},
  author = {Flatt, Matthew},
  year = {2002},
  month = sep,
  journal = {SIGPLAN Not.},
  volume = {37},
  number = {9},
  pages = {72--83},
  issn = {0362-1340},
  doi = {10.1145/583852.581486},
  urldate = {2025-06-23},
  abstract = {Many macro systems, especially for Lisp and Scheme, allow macro transformers to perform general computation. Moreover, the language for implementing compile-time macro transformers is usually the same as the language for implementing run-time functions. As a side effect of this sharing, implementations tend to allow the mingling of compile-time values and run-time values, as well as values from separate compilations. Such mingling breaks programming tools that must parse code without executing it. Macro implementors avoid harmful mingling by obeying certain macro-definition protocols and by inserting phase-distinguishing annotations into the code. However, the annotations are fragile, the protocols are not enforced, and programmers can only reason about the result in terms of the compiler's implementation. MzScheme---the language of the PLT Scheme tool suite---addresses the problem through a macro system that separates compilation without sacrificing the expressiveness of macros.},
  file = {C:\Users\caner\Zotero\storage\55CGSQJ9\Flatt - 2002 - Composable and compilable macros you want it when.pdf}
}

@article{flattMacrosThatWork2012,
  title = {Macros That {{Work Together}}: {{Compile-time}} Bindings, Partial Expansion, and Definition Contexts},
  shorttitle = {Macros That {{Work Together}}},
  author = {Flatt, Matthew and Culpepper, Ryan and Darais, David and Findler, Robert Bruce},
  year = {2012},
  month = mar,
  journal = {Journal of Functional Programming},
  volume = {22},
  number = {2},
  pages = {181--216},
  issn = {1469-7653, 0956-7968},
  doi = {10.1017/S0956796812000093},
  urldate = {2020-01-30},
  abstract = {Racket is a large language that is built mostly within itself. Unlike the usual approach taken by non-Lisp languages, the self-hosting of Racket is not a matter of bootstrapping one implementation through a previous implementation, but instead a matter of building a tower of languages and libraries via macros. The upper layers of the tower include a class system, a component system, pedagogic variants of Scheme, a statically typed dialect of Scheme, and more. The demands of this language-construction effort require a macro system that is substantially more expressive than previous macro systems. In particular, while conventional Scheme macro systems handle stand-alone syntactic forms adequately, they provide weak support for macros that share information or macros that use existing syntactic forms in new contexts. This paper describes and models features of the Racket macro system, including support for general compile-time bindings, sub-form expansion and analysis, and environment management. The presentation assumes a basic familiarity with Lisp-style macros, and it takes for granted the need for macros that respect lexical scope. The model, however, strips away the pattern and template system that is normally associated with Scheme macros, isolating a core that is simpler, can support pattern and template forms themselves as macros, and generalizes naturally to Racket's other extensions.},
  langid = {english},
  file = {C\:\\Users\\caner\\Zotero\\storage\\KJ3MZ6SZ\\Flatt et al. - 2012 - Macros that Work Together Compile-time bindings, .pdf;C\:\\Users\\caner\\Zotero\\storage\\9IWC2NZF\\375043C6746405B22014D235FA4C90C3.html}
}

@article{hayashizakiImprovingPerformanceTracebased2011,
  title = {Improving the Performance of Trace-Based Systems by False Loop Filtering},
  author = {Hayashizaki, Hiroshige and Wu, Peng and Inoue, Hiroshi and Serrano, Mauricio J. and Nakatani, Toshio},
  year = {2011},
  month = mar,
  journal = {ACM SIGPLAN Notices},
  volume = {46},
  number = {3},
  pages = {405--418},
  issn = {0362-1340, 1558-1160},
  doi = {10.1145/1961296.1950412},
  urldate = {2025-03-27},
  abstract = {Trace-based compilation is a promising technique for language compilers and binary translators. It offers the potential to expand the compilation scopes that have traditionally been limited by method boundaries.             Detecting repeating cyclic execution paths and capturing the detected repetitions into traces is a key requirement for trace selection algorithms to achieve good optimization and performance with small amounts of code. One important class of repetition detection is cyclic-path-based repetition detection, where a cyclic execution path (a path that starts and ends at the same instruction address) is detected as a repeating cyclic execution path.             However, we found many cyclic paths that are not repeating cyclic execution paths, which we call false loops. A common class of false loops occurs when a method is invoked from multiple call-sites. A cycle is formed between two invocations of the method from different call-sites, but which does not represent loops or recursion. False loops can result in shorter traces and smaller compilation scopes, and degrade the performance.             We propose false loop filtering, an approach to reject false loops in the repetition detection step of trace selection, and a technique called false loop filtering by call-stack-comparison, which rejects a cyclic path as a false loop if the call stacks at the beginning and the end of the cycle are different.             We applied false loop filtering to our trace-based Java™ JIT compiler that is based on IBM's J9 JVM. We found that false loop filtering achieved an average improvement of 16\% and 10\% for the DaCapo benchmark when applied to two baseline trace selection algorithms, respectively, with up to 37\% improvement for individual benchmarks. In the end, with false loop filtering, our trace-based JIT achieves a performance comparable to that of the method-based J9 JVM/JIT using the corresponding optimization level.},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\QQGFA4RB\Hayashizaki et al. - 2011 - Improving the performance of trace-based systems by false loop filtering.pdf}
}

@inproceedings{hotpath:06,
  title = {{{HotpathVM}}: {{An Effective JIT Compiler}} for {{Resource-constrained Devices}}},
  shorttitle = {{{HotpathVM}}},
  booktitle = {Proceedings of the {{2Nd International Conference}} on {{Virtual Execution Environments}}},
  author = {Gal, Andreas and Probst, Christian W. and Franz, Michael},
  year = {2006},
  series = {{{VEE}} '06},
  pages = {144--153},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1134760.1134780},
  urldate = {2019-11-16},
  abstract = {We present a just-in-time compiler for a Java VM that is small enough to fit on resource-constrained devices, yet is surprisingly effective. Our system dynamically identifies traces of frequently executed bytecode instructions (which may span several basic blocks across several methods) and compiles them via Static Single Assignment (SSA) construction. Our novel use of SSA form in this context allows to hoist instructions across trace side-exits without necessitating expensive compensation code in off-trace paths. The overall memory consumption (code and data) of our system is only 150 kBytes, yet benchmarks show a speedup that in some cases rivals heavy-weight just-in-time compilers.},
  isbn = {978-1-59593-332-4},
  keywords = {dynamic compilation,embedded and resource-constrained systems,mixed-mode interpretive compiled systems,software trace scheduling,static single assignment form,virtual machines},
  file = {C:\Users\caner\Zotero\storage\MUT26PBM\Gal et al. - 2006 - HotpathVM An Effective JIT Compiler for Resource-.pdf}
}

@article{icfp2019,
  title = {Rebuilding {{Racket}} on {{Chez Scheme}} ({{Experience Report}})},
  author = {Flatt, Matthew and Derici, Caner and Dybvig, R. Kent and Keep, Andrew W. and Massaccesi, Gustavo E. and Spall, Sarah and {Tobin-Hochstadt}, Sam and Zeppieri, Jon},
  year = {2019},
  month = jul,
  journal = {Proc. ACM Program. Lang.},
  volume = {3},
  number = {ICFP},
  pages = {78:1--78:15},
  issn = {2475-1421},
  doi = {10.1145/3341642},
  urldate = {2019-11-12},
  abstract = {We rebuilt Racket on Chez Scheme, and it works well\&mdash;as long as we're allowed a few patches to Chez Scheme. DrRacket runs, the Racket distribution can build itself, and nearly all of the core Racket test suite passes. Maintainability and performance of the resulting implementation are good, although some work remains to improve end-to-end performance. The least predictable part of our effort was how big the differences between Racket and Chez Scheme would turn out to be and how we would manage those differences. We expect Racket on Chez Scheme to become the main Racket implementation, and we encourage other language implementers to consider Chez Scheme as a target virtual machine.},
  keywords = {Racket,Scheme},
  file = {C:\Users\caner\Zotero\storage\76JHJJYP\Flatt et al. - 2019 - Rebuilding Racket on Chez Scheme (Experience Repor.pdf}
}

@inproceedings{izawaAmalgamatingDifferentJIT2020b,
  title = {Amalgamating Different {{JIT}} Compilations in a Meta-Tracing {{JIT}} Compiler Framework},
  booktitle = {Proceedings of the 16th {{ACM SIGPLAN International Symposium}} on {{Dynamic Languages}}},
  author = {Izawa, Yusuke and Masuhara, Hidehiko},
  year = {2020},
  month = nov,
  pages = {1--15},
  publisher = {ACM},
  address = {Virtual USA},
  doi = {10.1145/3426422.3426977},
  urldate = {2025-06-13},
  isbn = {978-1-4503-8175-8},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\WAKJ6FNQ\Izawa and Masuhara - 2020 - Amalgamating different JIT compilations in a meta-tracing JIT compiler framework.pdf}
}

@misc{izawaLightweightMethodGenerating2025,
  title = {A {{Lightweight Method}} for {{Generating Multi-Tier JIT Compilation Virtual Machine}} in a {{Meta-Tracing Compiler Framework}}},
  author = {Izawa, Yusuke and Masuhara, Hidehiko and {Bolz-Tereick}, Carl Friedrich},
  year = {2025},
  month = apr,
  number = {arXiv:2504.17460},
  eprint = {2504.17460},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.17460},
  urldate = {2025-05-28},
  abstract = {Meta-compiler frameworks, such as RPython and Graal/Truffle, generate high-performance virtual machines (VMs) from interpreter definitions. Although they generate VMs with high-quality just-in-time (JIT) compilers, they still lack an important feature that dedicated VMs (i.e., VMs that are developed for specific languages) have, namely {\textbackslash}emph\{multi-tier compilation\}. Multi-tier compilation uses light-weight compilers at early stages and highly-optimizing compilers at later stages in order to balance between compilation overheads and code quality. We propose a novel approach to enabling multi-tier compilation in the VMs generated by a meta-compiler framework. Instead of extending the JIT compiler backend of the framework, our approach drives an existing (heavyweight) compiler backend in the framework to quickly generate unoptimized native code by merely embedding directives and compile-time operations into interpreter definitions. As a validation of the approach, we developed 2SOM, a Simple Object Machine with a two-tier JIT compiler based on RPython. 2SOM first applies the tier-1 threaded code generator that is generated by our proposed technique, then, to the loops that exceed a threshold, applies the tier-2 tracing JIT compiler that is generated by the original RPython framework. Our performance evaluation that runs a program with a realistic workload showed that 2SOM improved, when compared against an RPython-based VM, warm-up performance by 15{\textbackslash}\%, with merely a 5{\textbackslash}\% reduction in peak performance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Programming Languages},
  file = {C\:\\Users\\caner\\Zotero\\storage\\SX29ZQUE\\Izawa et al. - 2025 - A Lightweight Method for Generating Multi-Tier JIT Compilation Virtual Machine in a Meta-Tracing Com.pdf;C\:\\Users\\caner\\Zotero\\storage\\7WFHXFWI\\2504.html}
}

@article{jit-history:03,
  title = {A {{Brief History}} of {{Just-in-time}}},
  author = {Aycock, John},
  year = {2003},
  month = jun,
  journal = {ACM Comput. Surv.},
  volume = {35},
  number = {2},
  pages = {97--113},
  issn = {0360-0300},
  doi = {10.1145/857076.857077},
  urldate = {2019-12-01},
  abstract = {Software systems have been using "just-in-time" compilation (JIT) techniques since the 1960s. Broadly, JIT compilation includes any translation performed dynamically, after a program has started execution. We examine the motivation behind JIT compilation and constraints imposed on JIT compilation systems, and present a classification scheme for such systems. This classification emerges as we survey forty years of JIT work, from 1960--2000.},
  keywords = {dynamic compilation,Just-in-time compilation},
  file = {C:\Users\caner\Zotero\storage\48RY7S5V\Aycock - 2003 - A Brief History of Just-in-time.pdf}
}

@inproceedings{loop-aware:12,
  title = {Loop-Aware {{Optimizations}} in {{PyPy}}'s {{Tracing JIT}}},
  booktitle = {Proceedings of the 8th {{Symposium}} on {{Dynamic Languages}}},
  author = {akan Ard{\"o}, H{\textbackslash}a and Bolz, Carl Friedrich and FijaBkowski, Maciej},
  year = {2012},
  series = {{{DLS}} '12},
  pages = {63--72},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/2384577.2384586},
  urldate = {2019-03-22},
  abstract = {One of the nice properties of a tracing just-in-time compiler (JIT) is that many of its optimizations are simple, requiring one forward pass only. This is not true for loop-invariant code motion which is a very important optimization for code with tight kernels. Especially for dynamic languages that typically perform quite a lot of loop invariant type checking, boxed value unwrapping and virtual method lookups. In this paper we explain a scheme pioneered within the context of the LuaJIT project for making basic optimizations loop-aware by using a simple pre-processing step on the trace without changing the optimizations themselves. We have implemented the scheme in RPython's tracing JIT compiler. PyPy's Python JIT executing simple numerical kernels can become up to two times faster, bringing the performance into the ballpark of static language compilers.},
  isbn = {978-1-4503-1564-7},
  keywords = {loop-invariant code motion,optimization,tracing JIT},
  file = {C:\Users\caner\Zotero\storage\QSMR5HNR\Ardö et al. - 2012 - Loop-aware Optimizations in PyPy's Tracing JIT.pdf}
}

@inproceedings{malloc-removal:11,
  title = {Allocation {{Removal}} by {{Partial Evaluation}} in a {{Tracing JIT}}},
  booktitle = {Proceedings of the 20th {{ACM SIGPLAN Workshop}} on {{Partial Evaluation}} and {{Program Manipulation}}},
  author = {Bolz, Carl Friedrich and Cuni, Antonio and FijaBkowski, Maciej and Leuschel, Michael and Pedroni, Samuele and Rigo, Armin},
  year = {2011},
  series = {{{PEPM}} '11},
  pages = {43--52},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1929501.1929508},
  urldate = {2019-11-16},
  abstract = {The performance of many dynamic language implementations suffers from high allocation rates and runtime type checks. This makes dynamic languages less applicable to purely algorithmic problems, despite their growing popularity. In this paper we present a simple compiler optimization based on online partial evaluation to remove object allocations and runtime type checks in the context of a tracing JIT. We evaluate the optimization using a Python VM and find that it gives good results for all our (real-life) benchmarks.},
  isbn = {978-1-4503-0485-6},
  keywords = {optimization,partial evaluation,tracing jit},
  file = {C:\Users\caner\Zotero\storage\7GRXDUIE\Bolz et al. - 2011 - Allocation Removal by Partial Evaluation in a Trac.pdf}
}

@misc{mozblog,
  title = {You Lose More When Slow than You Gain When Fast -- {{Nicholas Nethercote}}},
  urldate = {2025-06-12},
  howpublished = {https://blog.mozilla.org/nnethercote/2011/05/31/you-lose-more-when-slow-than-you-gain-when-fast/},
  file = {C:\Users\caner\Zotero\storage\RG2D8I54\you-lose-more-when-slow-than-you-gain-when-fast.html}
}

@inproceedings{practical-partial,
  title = {Practical Partial Evaluation for High-Performance Dynamic Language Runtimes},
  booktitle = {Proceedings of the 38th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {W{\"u}rthinger, Thomas and Wimmer, Christian and Humer, Christian and W{\"o}{\ss}, Andreas and Stadler, Lukas and Seaton, Chris and Duboscq, Gilles and Simon, Doug and Grimmer, Matthias},
  year = {2017},
  month = jun,
  pages = {662--676},
  publisher = {ACM},
  address = {Barcelona Spain},
  doi = {10.1145/3062341.3062381},
  urldate = {2025-06-17},
  abstract = {Most high-performance dynamic language virtual machines duplicate language semantics in the interpreter, compiler, and runtime system. This violates the principle to not repeat yourself. In contrast, we define languages solely by writing an interpreter. The interpreter performs specializations, e.g., augments the interpreted program with type information and profiling information. Compiled code is derived automatically using partial evaluation while incorporating these specializations. This makes partial evaluation practical in the context of dynamic languages: It reduces the size of the compiled code while still compiling all parts of an operation that are relevant for a particular program. When a speculation fails, execution transfers back to the interpreter, the program re-specializes in the interpreter, and later partial evaluation again transforms the new state of the interpreter to compiled code. We evaluate our approach by comparing our implementations of JavaScript, Ruby, and R with best-inclass specialized production implementations. Our generalpurpose compilation system is competitive with production systems even when they have been heavily optimized for the one language they support. For our set of benchmarks, our speedup relative to the V8 JavaScript VM is 0.83x, relative to JRuby is 3.8x, and relative to GNU R is 5x.},
  isbn = {978-1-4503-4988-8},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\8V8IYVQT\Würthinger et al. - 2017 - Practical partial evaluation for high-performance dynamic language runtimes.pdf}
}

@inproceedings{pycketmain,
  title = {Pycket: {{A Tracing JIT}} for a {{Functional Language}}},
  shorttitle = {Pycket},
  booktitle = {Proceedings of the 20th {{ACM SIGPLAN International Conference}} on {{Functional Programming}}},
  author = {Bauman, Spenser and Bolz, Carl Friedrich and Hirschfeld, Robert and Kirilichev, Vasily and Pape, Tobias and Siek, Jeremy G. and {Tobin-Hochstadt}, Sam},
  year = {2015},
  series = {{{ICFP}} 2015},
  pages = {22--34},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/2784731.2784740},
  urldate = {2019-03-22},
  abstract = {We present Pycket, a high-performance tracing JIT compiler for Racket. Pycket supports a wide variety of the sophisticated features in Racket such as contracts, continuations, classes, structures, dynamic binding, and more. On average, over a standard suite of benchmarks, Pycket outperforms existing compilers, both Racket's JIT and other highly-optimizing Scheme compilers. Further, Pycket provides much better performance for Racket proxies than existing systems, dramatically reducing the overhead of contracts and gradual typing. We validate this claim with performance evaluation on multiple existing benchmark suites. The Pycket implementation is of independent interest as an application of the RPython meta-tracing framework (originally created for PyPy), which automatically generates tracing JIT compilers from interpreters. Prior work on meta-tracing focuses on bytecode interpreters, whereas Pycket is a high-level interpreter based on the CEK abstract machine and operates directly on abstract syntax trees. Pycket supports proper tail calls and first-class continuations. In the setting of a functional language, where recursion and higher-order functions are more prevalent than explicit loops, the most significant performance challenge for a tracing JIT is identifying which control flows constitute a loop---we discuss two strategies for identifying loops and measure their impact.},
  isbn = {978-1-4503-3669-7},
  keywords = {contracts,functional languages,JIT compilers,Racket,tracing},
  file = {C:\Users\caner\Zotero\storage\2JP3BUTY\Bauman et al. - 2015 - Pycket A Tracing JIT for a Functional Language.pdf}
}

@article{pycketmain2,
  title = {Sound Gradual Typing: Only Mostly Dead},
  shorttitle = {Sound Gradual Typing},
  author = {Bauman, Spenser and {Bolz-Tereick}, Carl Friedrich and Siek, Jeremy and {Tobin-Hochstadt}, Sam},
  year = {2017},
  month = oct,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {1},
  number = {OOPSLA},
  pages = {1--24},
  issn = {24751421},
  doi = {10.1145/3133878},
  urldate = {2019-11-10},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\DSSSEG9Z\Bauman et al. - 2017 - Sound gradual typing only mostly dead.pdf}
}

@inproceedings{pypy-main,
  title = {Tracing the {{Meta-level}}: {{PyPy}}'s {{Tracing JIT Compiler}}},
  shorttitle = {Tracing the {{Meta-level}}},
  booktitle = {Proceedings of the 4th {{Workshop}} on the {{Implementation}}, {{Compilation}}, {{Optimization}} of {{Object-Oriented Languages}} and {{Programming Systems}}},
  author = {Bolz, Carl Friedrich and Cuni, Antonio and Fijalkowski, Maciej and Rigo, Armin},
  year = {2009},
  series = {{{ICOOOLPS}} '09},
  pages = {18--25},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1565824.1565827},
  urldate = {2019-03-22},
  abstract = {We attempt to apply the technique of Tracing JIT Compilers in the context of the PyPy project, i.e., to programs that are interpreters for some dynamic languages, including Python. Tracing JIT compilers can greatly speed up programs that spend most of their time in loops in which they take similar code paths. However, applying an unmodified tracing JIT to a program that is itself a bytecode interpreter results in very limited or no speedup. In this paper we show how to guide tracing JIT compilers to greatly improve the speed of bytecode interpreters. One crucial point is to unroll the bytecode dispatch loop, based on two kinds of hints provided by the implementer of the bytecode interpreter. We evaluate our technique by applying it to two PyPy interpreters: one is a small example, and the other one is the full Python interpreter.},
  isbn = {978-1-60558-541-3},
  file = {C:\Users\caner\Zotero\storage\ZW64A5W8\Bolz et al. - 2009 - Tracing the Meta-level PyPy's Tracing JIT Compile.pdf}
}

@inproceedings{pypy06,
  title = {{{PyPy}}'s {{Approach}} to {{Virtual Machine Construction}}},
  booktitle = {Companion to the 21st {{ACM SIGPLAN Symposium}} on {{Object-oriented Programming Systems}}, {{Languages}}, and {{Applications}}},
  author = {Rigo, Armin and Pedroni, Samuele},
  year = {2006},
  series = {{{OOPSLA}} '06},
  pages = {944--953},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1176617.1176753},
  urldate = {2019-11-12},
  abstract = {The PyPy project seeks to prove both on a research and a practical level the feasibility of constructing a virtual machine (VM) for a dynamic language in a dynamic language - in this case, Python. The aim is to translate (i.e. compile) the VM to arbitrary target environments, ranging in level from C/Posix to Smalltalk/Squeak via Java and CLI/.NET, while still being of reasonable efficiency within these environments.A key tool to achieve this goal is the systematic reuse of the Python language as a system programming language at various levels of our architecture and translation process. For each level, we design a corresponding type system and apply a generic type inference engine - for example, the garbage collector is written in a style that manipulates simulated pointer and address objects, and when translated to C these operations become C-level pointer and address instructions.},
  isbn = {978-1-59593-491-8},
  keywords = {metacircularity,Python,retargettable code generation,type inference,virtual machine},
  file = {C:\Users\caner\Zotero\storage\ALGTU6SG\Rigo and Pedroni - 2006 - PyPy's Approach to Virtual Machine Construction.pdf}
}

@misc{pypy08,
  title = {The {{Architecture}} of {{Open Source Applications}} ({{Volume}} 2): {{PyPy}}},
  urldate = {2019-11-12},
  howpublished = {https://www.aosabook.org/en/pypy.html},
  file = {C:\Users\caner\Zotero\storage\B2QBSUWA\pypy.html}
}

@inproceedings{rpython07,
  title = {{{RPython}}: {{A Step Towards Reconciling Dynamically}} and {{Statically Typed OO Languages}}},
  shorttitle = {{{RPython}}},
  booktitle = {Proceedings of the 2007 {{Symposium}} on {{Dynamic Languages}}},
  author = {Ancona, Davide and Ancona, Massimo and Cuni, Antonio and Matsakis, Nicholas D.},
  year = {2007},
  series = {{{DLS}} '07},
  pages = {53--64},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1297081.1297091},
  urldate = {2019-11-12},
  abstract = {Although the C-based interpreter of Python is reasonably fast, implementations on the CLI or the JVM platforms offers some advantages in terms of robustness and interoperability. Unfortunately, because the CLI and JVM are primarily designed to execute statically typed, object-oriented languages, most dynamic language implementations cannot use the native bytecodes for common operations like method calls and exception handling; as a result, they are not able to take full advantage of the power offered by the CLI and JVM. We describe a different approach that attempts to preserve the flexibility of Python, while still allowing for efficient execution. This is achieved by limiting the use of the more dynamic features of Python to an initial, bootstrapping phase. This phase is used to construct a final RPython (Restricted Python) program that is actually executed. RPython is a proper subset of Python, is statically typed, and does not allow dynamic modification of class or method definitions; however, it can still take advantage of Python features such as mixins and first-class methods and classes. This paper presents an overview of RPython, including its design and its translation to both CLI and JVM bytecode. We show how the bootstrapping phase can be used to implement advanced features, like extensible classes and generative programming. We also discuss what work remains before RPython is truly ready for general use, and compare the performance of RPython with that of other approaches.},
  isbn = {978-1-59593-868-8},
  keywords = {.NET,JVM,Python},
  file = {C:\Users\caner\Zotero\storage\MVZCMYBI\Ancona et al. - 2007 - RPython A Step Towards Reconciling Dynamically an.pdf}
}

@inproceedings{rpython09,
  title = {{{PyGirl}}: {{Generating Whole-System VMs}} from High-Level Models Using {{PyPy}}},
  shorttitle = {{{PyGirl}}},
  author = {Bruni, Camillo and Verwaest, Toon},
  year = {2009},
  month = jun,
  volume = {33},
  pages = {328--347},
  doi = {10.1007/978-3-642-02571-6_19},
  abstract = {Virtual machines (VMs) emulating hardware devices are generally implemented in low-level languages for performance reasons. This results in unmaintainable systems that are difficult to understand. In this paper we report on our experience using the PyPy toolchain to improve the portability and reduce the complexity of whole-system VM implementations. As a case study we implement a VM prototype for a Nintendo Game Boy, called PyGirl, in which the high-level model is separated from low-level VM implementation issues. We shed light on the process of refactoring from a low-level VM implementation in Java to a high-level model in RPython. We show that our whole-system VM written with PyPy is significantly less complex than standard implementations, without substantial loss in performance.},
  file = {C:\Users\caner\Zotero\storage\ESEZHPD5\Bruni and Verwaest - 2009 - PyGirl Generating Whole-System VMs from high-leve.pdf}
}

@article{samth:11,
  title = {Languages as Libraries},
  author = {{Tobin-Hochstadt}, Sam and {St-Amour}, Vincent and Culpepper, Ryan and Flatt, Matthew and Felleisen, Matthias},
  pages = {10},
  abstract = {Programming language design benefits from constructs for extending the syntax and semantics of a host language. While C's stringbased macros empower programmers to introduce notational shorthands, the parser-level macros of Lisp encourage experimentation with domain-specific languages. The Scheme programming language improves on Lisp with macros that respect lexical scope.},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\Y47HQ2G4\Tobin-Hochstadt et al. - Languages as libraries.pdf}
}

@inproceedings{schneiderEfficientHandlingGuards2012,
  title = {The Efficient Handling of Guards in the Design of {{RPython}}'s Tracing {{JIT}}},
  booktitle = {Proceedings of the Sixth {{ACM}} Workshop on {{Virtual}} Machines and Intermediate Languages},
  author = {Schneider, David and Bolz, Carl Friedrich},
  year = {2012},
  month = oct,
  pages = {3--12},
  publisher = {ACM},
  address = {Tucson Arizona USA},
  doi = {10.1145/2414740.2414743},
  urldate = {2025-06-20},
  isbn = {978-1-4503-1633-0},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\EWXZMD8Y\Schneider and Bolz - 2012 - The efficient handling of guards in the design of RPython's tracing JIT.pdf}
}

@inproceedings{schneiderEfficientHandlingGuards2012a,
  title = {The Efficient Handling of Guards in the Design of {{RPython}}'s Tracing {{JIT}}},
  booktitle = {Proceedings of the Sixth {{ACM}} Workshop on {{Virtual}} Machines and Intermediate Languages},
  author = {Schneider, David and Bolz, Carl Friedrich},
  year = {2012},
  month = oct,
  series = {{{VMIL}} '12},
  pages = {3--12},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2414740.2414743},
  urldate = {2025-06-20},
  abstract = {Tracing just-in-time (JIT) compilers record linear control flow paths, inserting operations called guards at points of possible divergence. These operations occur frequently in generated traces and therefore it is important to design and implement them carefully to find the right trade-off between deoptimization, memory overhead, and (partly) execution speed. In this paper, we perform an empirical analysis of runtime properties of guards. This is used to guide the design of guards in the RPython tracing JIT.},
  isbn = {978-1-4503-1633-0},
  file = {C:\Users\caner\Zotero\storage\2PWWZY7I\Schneider and Bolz - 2012 - The efficient handling of guards in the design of RPython's tracing JIT.pdf}
}

@article{survey:05,
  title = {A {{Survey}} of {{Adaptive Optimization}} in {{Virtual Machines}}},
  author = {Arnold, M. and Fink, S. J. and Grove, D. and Hind, M. and Sweeney, P. F.},
  year = {2005},
  month = feb,
  journal = {Proceedings of the IEEE},
  volume = {93},
  number = {2},
  pages = {449--466},
  issn = {0018-9219},
  doi = {10.1109/JPROC.2004.840305},
  abstract = {Virtual machines face significant performance challenges beyond those confronted by traditional static optimizers. First, portable program representations and dynamic language features, such as dynamic class loading, force the deferral of most optimizations until runtime, inducing runtime optimization overhead. Second, modular program representations preclude many forms of whole-program interprocedural optimization. Third, virtual machines incur additional costs for runtime services such as security guarantees and automatic memory management. To address these challenges, vendors have invested considerable resources into adaptive optimization systems in production virtual machines. Today, mainstream virtual machine implementations include substantial infrastructure for online monitoring and profiling, runtime compilation, and feedback-directed optimization. As a result, adaptive optimization has begun to mature as a widespread production-level technology. This paper surveys the evolution and current state of adaptive optimization technology in virtual machines.},
  keywords = {Adaptive optimization,adaptive optimization systems,Adaptive systems,automatic memory management,Condition monitoring,Costs,dynamic optimization,feedback directed optimization,feedback-directed optimization (FDO),Memory management,modular program representations,online monitoring,online profiling,optimisation,optimising compilers,optimization,Optimized production technology,production level technology,Production systems,Runtime,runtime compilation,Security,software performance evaluation,static optimizers,Virtual machine monitors,virtual machines,Virtual machining},
  file = {C\:\\Users\\caner\\Zotero\\storage\\DVWJXGSE\\Arnold et al. - 2005 - A Survey of Adaptive Optimization in Virtual Machi.pdf;C\:\\Users\\caner\\Zotero\\storage\\I5PPYRYM\\1386662.html}
}

@inproceedings{trace-vs-PE,
  title = {Tracing vs. Partial Evaluation: Comparing Meta-Compilation Approaches for Self-Optimizing Interpreters},
  shorttitle = {Tracing vs. Partial Evaluation},
  booktitle = {Proceedings of the 2015 {{ACM SIGPLAN International Conference}} on {{Object-Oriented Programming}}, {{Systems}}, {{Languages}}, and {{Applications}} - {{OOPSLA}} 2015},
  author = {Marr, Stefan and Ducasse, St{\'e}phane},
  year = {2015},
  pages = {821--839},
  publisher = {ACM Press},
  address = {Pittsburgh, PA, USA},
  doi = {10.1145/2814270.2814275},
  urldate = {2019-03-28},
  isbn = {978-1-4503-3689-5},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\U6CTI5AY\Marr and Ducasse - 2015 - Tracing vs. partial evaluation comparing meta-com.pdf}
}

@inproceedings{traceMonkey,
  title = {Trace-Based {{Just-in-time Type Specialization}} for {{Dynamic Languages}}},
  booktitle = {Proceedings of the 30th {{ACM SIGPLAN Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Gal, Andreas and Eich, Brendan and Shaver, Mike and Anderson, David and Mandelin, David and Haghighat, Mohammad R. and Kaplan, Blake and Hoare, Graydon and Zbarsky, Boris and Orendorff, Jason and Ruderman, Jesse and Smith, Edwin W. and Reitmaier, Rick and Bebenita, Michael and Chang, Mason and Franz, Michael},
  year = {2009},
  series = {{{PLDI}} '09},
  pages = {465--478},
  publisher = {ACM},
  address = {New York, NY, USA},
  doi = {10.1145/1542476.1542528},
  urldate = {2019-11-28},
  abstract = {Dynamic languages such as JavaScript are more difficult to compile than statically typed ones. Since no concrete type information is available, traditional compilers need to emit generic code that can handle all possible type combinations at runtime. We present an alternative compilation technique for dynamically-typed languages that identifies frequently executed loop traces at run-time and then generates machine code on the fly that is specialized for the actual dynamic types occurring on each path through the loop. Our method provides cheap inter-procedural type specialization, and an elegant and efficient way of incrementally compiling lazily discovered alternative paths through nested loops. We have implemented a dynamic compiler for JavaScript based on our technique and we have measured speedups of 10x and more for certain benchmark programs.},
  isbn = {978-1-60558-392-1},
  keywords = {dynamically typed languages,trace-based compilation},
  file = {C:\Users\caner\Zotero\storage\FWYDACR5\Gal et al. - 2009 - Trace-based Just-in-time Type Specialization for D.pdf}
}

@inproceedings{truffle-graal,
  title = {One {{VM}} to Rule Them All},
  booktitle = {Proceedings of the 2013 {{ACM}} International Symposium on {{New}} Ideas, New Paradigms, and Reflections on Programming \& Software - {{Onward}}! '13},
  author = {W{\"u}rthinger, Thomas and Wimmer, Christian and W{\"o}{\ss}, Andreas and Stadler, Lukas and Duboscq, Gilles and Humer, Christian and Richards, Gregor and Simon, Doug and Wolczko, Mario},
  year = {2013},
  pages = {187--204},
  publisher = {ACM Press},
  address = {Indianapolis, Indiana, USA},
  doi = {10.1145/2509578.2509581},
  urldate = {2019-11-25},
  abstract = {Building high-performance virtual machines is a complex and expensive undertaking; many popular languages still have low-performance implementations. We describe a new approach to virtual machine (VM) construction that amortizes much of the effort in initial construction by allowing new languages to be implemented with modest additional effort. The approach relies on abstract syntax tree (AST) interpretation where a node can rewrite itself to a more specialized or more general node, together with an optimizing compiler that exploits the structure of the interpreter. The compiler uses speculative assumptions and deoptimization in order to produce efficient machine code. Our initial experience suggests that high performance is attainable while preserving a modular and layered architecture, and that new highperformance language implementations can be obtained by writing little more than a stylized interpreter.},
  isbn = {978-1-4503-2472-4},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\7JJNARJ3\Würthinger et al. - 2013 - One VM to rule them all.pdf}
}

@article{typeSpecial:2009,
  title = {Trace-Based Just-in-Time Type Specialization for Dynamic Languages},
  author = {Gal, Andreas and Eich, Brendan and Shaver, Mike and Anderson, David and Mandelin, David and Haghighat, Mohammad R. and Kaplan, Blake and Hoare, Graydon and Zbarsky, Boris and Orendorff, Jason and Ruderman, Jesse and Smith, Edwin W. and Reitmaier, Rick and Bebenita, Michael and Chang, Mason and Franz, Michael},
  year = {2009},
  month = jun,
  journal = {SIGPLAN Not.},
  volume = {44},
  number = {6},
  pages = {465--478},
  issn = {0362-1340},
  doi = {10.1145/1543135.1542528},
  urldate = {2025-06-23},
  abstract = {Dynamic languages such as JavaScript are more difficult to compile than statically typed ones. Since no concrete type information is available, traditional compilers need to emit generic code that can handle all possible type combinations at runtime. We present an alternative compilation technique for dynamically-typed languages that identifies frequently executed loop traces at run-time and then generates machine code on the fly that is specialized for the actual dynamic types occurring on each path through the loop. Our method provides cheap inter-procedural type specialization, and an elegant and efficient way of incrementally compiling lazily discovered alternative paths through nested loops. We have implemented a dynamic compiler for JavaScript based on our technique and we have measured speedups of 10x and more for certain benchmark programs.},
  file = {C:\Users\caner\Zotero\storage\T59L5B5Z\Gal et al. - 2009 - Trace-based just-in-time type specialization for dynamic languages.pdf}
}

@article{vandercammenEssenceMetaTracingJIT,
  title = {The {{Essence}} of {{Meta-Tracing JIT Compilers}}},
  author = {Vandercammen, Maarten},
  langid = {english},
  file = {C:\Users\caner\Zotero\storage\9Q858YLX\Vandercammen - The Essence of Meta-Tracing JIT Compilers.pdf}
}
