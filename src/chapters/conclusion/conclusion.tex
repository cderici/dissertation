\chapter[\texorpdfstring{CONCLUSION \& SIGNIFICANCE}
                          {8. Conclusion}]{CONCLUSION \& SIGNIFICANCE}

    \label{chapter:conclusion}

    \begin{chaptersynopsis}[Chapter Synopsis]
        \footnotesize

        Thesis:

        \textit{Efficient self-hosting of full-scale functional languages on meta-tracing \gls{jit} compilers is achievable.}

        We:

        1. provided a full-scale, self-hosting functional programming language on a meta-tracing \gls{jit} compiler as evidence.

        2. provided, for the first time, a formal specification of the operational semantics of linklets.

        3. exposed performance issues fundamental to self-hosting on meta-tracing \gls{jit} compilers, and provided solution approaches.

        4. argued that guiding the tracer away from branch-heavy computations can improve performance of tracing interpreter-style, data-dependent code.

        5. presented and detailed a technique that uses hybrid computational models in language run-times to improve performance.

        \vspace{2em}

        Sections:
		\begin{itemize}
			\item Related Work
			\item Future Work
		\end{itemize}
    \end{chaptersynopsis}

    \paragraph{} \textit{Thesis:}

    \textit{Efficient self-hosting of a full-scale functional language on a meta-tracing \gls{jit} compiler is achievable.}

    \paragraph{}% 1
        In this dissertation, we provided reproducible evidence demonstrating the feasibility of efficiently implementing a full-scale, self-hosting functional programming language on a meta-tracing \gls{jit} compiler. This claim was substantiated through multiple key contributions, which we summarize below.

    \paragraph{}% 2 - pycket
        We developed Pycket, a practical research vehicle, transforming it from a rudimentary interpreter for Racket's \racketcode{#\%kernel} language into a complete runtime system capable of supporting Racket. Pycket's evolution and the critical implementation details are discussed comprehensively in \chapterRef{chapter:pycket}, and the correctness and completeness of this transformation are validated in \chapterRef{chapter:validation}.

    \paragraph{}% 3 - linklets
        We provided, for the first time, a formal specification of the operational semantics of linklets, a core compilation unit that facilitates improved interaction between the compiler and the run-time, thereby enhancing the portability of Racket. This formalization is described in \chapterRef{chapter:linklets}, with the complete model in PLT Redex presented in \appendixRef{appendix:linklet-semantics-model-redex-code}.

    \paragraph{}% 4
        Although a definitive proof of efficiency remains an open problem, we identified and analyzed performance issues fundamental to self-hosting on meta-tracing \gls{jit} compilers in \chapterRef{chapter:problem}. In \chapterRef{chapter:solution}, we proposed solution approaches to these significant issues, acknowledging that fully resolving them would require extensive further work. We provided initial evidence indicating that these approaches warrant additional investigation.

    \paragraph{}% 5 - hot branches
        We contributed to the performance analysis of tracing \glspl{jit} by proposing more fine-grained control over tracing loops involving deep branching. Specifically, in \chapterRef{chapter:solution}, we argued that guiding the tracer away from computations heavy with branches can improve the overall performance of tracing interpreter-style, data-dependent code.

    \paragraph{}% 6 - hybrid
        Additionally, we presented a new perspective on computational models in language run-times. In \chapterRef{chapter:solution}, we argued for combining different kinds of reducers rather than committing to a single evaluation model. By leveraging the complementary strengths of multiple evaluation strategies, this hybrid approach has the potential to improve the overall performance of language \glspl{vm}.

    \section{Related Work}
        \label{section:related-work}

        \paragraph{Higher-order dynamic VMs}% 7
            Dynamic \gls{vm} implementations have gained popularity due to their potential for rapid prototyping, given the high effort involved in implementing new VMs from scratch. Instead of building a \gls{vm} manually in low-level languages like C, researchers frequently utilize existing general-purpose object-oriented \glspl{vm} or dynamically generate VMs from high-level specifications. A prominent example is the \emph{GraalVM}, which is a modified Java HotSpot \gls{vm} that leverages the Truffle framework and the method-based Graal \gls{jit} compiler to implement languages such as JavaScript, Ruby, and Python~\cite{truffle-graal}. In contrast, the RPython project introduced automatic \gls{vm} generation from interpreter specifications via meta-tracing~\cite{rpython07}. PyPy, built using RPython, has demonstrated better performance than CPython itself. Other notable meta-tracing systems include \emph{SPUR}, a tracing \gls{jit} for CIL bytecode~\cite{spurJIT,millerCommonLanguageInfrastructure2003}.

        \paragraph{Tracing JIT VMs}% 8
            Pycket, similar to PyPy, is built upon the RPython meta-tracing framework. Our research focuses on efficient self-hosting within Pycket. Trace-based compilation, initially introduced by the Dynamo project~\cite{dynamo}, has seen successful application in several commercial \glspl{vm} such as Mozilla's \emph{TraceMonkey} JavaScript \gls{vm}~\cite{traceMonkey} and Adobe's \emph{Tamarin} ActionScript \gls{vm}~\cite{tamarin}, as well as in research-focused implementations like \emph{LuaJIT}~\cite{LuaJITLanguageToolkit}, \emph{Converge}~\cite{converge:05}, \emph{Lambdamachine}~\cite{lambdamachine}, and \emph{PyHaskell}~\cite{pyhaskell}.

        \paragraph{Optimizing VM performance in a meta-tracing context}% 9
            As we mentioned in \chapterRef{chapter:rpython}, the \emph{RPython} backend dynamically performs various optimizations, which require alignment with the language interpreter. \gls{vm} authors typically optimize such systems by either improving interpreter performance directly or by modifying interpreters to produce traces that are more easily optimized by the \gls{jit}. Both methods act on the interpreter itself, so improvements typically focus on language-specific patterns. Alongside general \gls{jit} improvements such as value promotion and elidable functions, projects like \emph{PyPy} and \emph{Converge} specifically optimize object, class, and module handling to enhance their performance~\cite{bolz15-meta-vm}.

        \paragraph{Self-hosting}% 10
            Bolz et al.\ argue that achieving good performance in general-purpose \glspl{vm} requires semantic alignment between the implemented language and its compiler~\cite{bolzHowNotWrite, runtime-feedback:11}. Our investigation in \chapterRef{chapter:problem} similarly studies the relationship between program semantics specific to self-hosting and interpreter performance on tracing \glspl{jit}. To our knowledge, no other work specifically examines self-hosting in meta-tracing frameworks. However, existing self-hosting systems for dynamic languages, such as the \emph{Tachyon} JavaScript \gls{vm}, implement bootstrapping compilers entirely by hand-coding in their own languages without automatic generation techniques~\cite{self-hosted-tachyon}. Although \emph{Tachyon} differs significantly from \emph{Pycket}, it shares some similarities, such as the use of \glspl{cfg} in \gls{ssa} form as \gls{ir}. Moreover, techniques like conditional constant propagation through abstract interpretation~\cite{sccp:91} and low-level optimizations addressing indirect branching~\cite{branch-predict:03} could potentially be adapted to tracing contexts, though our approach specifically targets the language interpreter level, rather than modifications to the underlying \emph{RPython} framework.

        \paragraph{Managing abstraction levels}% 11
            A substantial part of the problems addressed in this thesis arises due to the added abstraction level introduced by self-hosting \emph{Racket}, requiring careful semantic alignment with the underlying meta-tracing \gls{vm}. Related research has focused on reducing complexity in multi-level abstraction systems, using techniques such as type-directed partial evaluation~\cite{tdpe:99} and multi-stage programming~\cite{multi-stage:17}. Amin and Rompf, for instance, explored how interpreter towers can be collapsed into compilers to eliminate interpretation overhead, introducing a multi-level lambda calculus and the meta-circular evaluator \emph{Pink} to demonstrate this idea~\cite{collapse:17}. Another relevant approach, explored by Yermolovich et al., involves trace-based optimization of hierarchically layered \glspl{vm}, such as running the guest \emph{Lua VM}\cite{LuaJITLanguageToolkit} atop the host \emph{Tamarin} \gls{vm}\cite{tamarin}. Their approach allowed the guest \gls{vm} to communicate hints about interpreter loops, specifying code sections the host \gls{vm} should avoid tracing independently, thus considering the workload of the guest \gls{vm}.

        \paragraph{Space concerns \& heap allocated continuations}% 12
            Many studies investigate the relationship between space complexity and performance optimizations in language implementations. Some utilize \emph{repurposed} \glspl{jit} (RJIT) to leverage dynamic language optimizations, such as simplifying \glspl{cfg}\cite{dynStatComp:12} or applying run-time type feedback\cite{stJITdyn:12}, particularly when adding dynamic language support to existing static-language \glspl{vm}.

        \paragraph{}%
            Higher-level approaches also address these concerns. For instance, \emph{Pycket} employs hidden classes~\cite{pycketmain2}, which are conceptually similar to maps introduced by the \emph{Self} project~\cite{self-maps:89} and adopted by \emph{PyPy} as well \cite{runtime-feedback:11}.

        \paragraph{}%
            In our work, garbage collection overhead caused by long chains of heap-allocated continuations was identified as a significant issue in self-hosting. Allocating activation records on the heap has been extensively studied within compiler contexts, both with explicit continuations~\cite{comp-cont:92} and without them~\cite{comp-without-cont:17,whatever:19}.

        \paragraph{}%
            Perhaps most relevant to our investigation involving both stackful and CEK interpreters is the work by Hieb et al.~\cite{cont-heap-stack:90}, who proposed allocating activation records on the stack without requiring extensive copying when continuations are created. Their approach bounds the amount of copying, which is otherwise potentially unbounded, and also offers techniques for stack overflow and underflow recovery, equivalent to continuation creation and re-instantiation.

        \paragraph{}%
            To our knowledge, no comprehensive synthesis addressing the challenges and opportunities of self-hosting on a meta-tracing \gls{vm} exists in the literature. Consequently, direct comparative evaluations with systems identical to \emph{Pycket} are currently impossible. Nonetheless, existing Racket implementations, such as its previous generic \gls{jit}-based VM and the current \emph{Chez}-based implementation~\cite{icfp2019}, offer suitable targets for performance comparison involving computations emphasizing different language features across programs with varying characteristics.


    \section[\texorpdfstring{Future Work}{Future Work}]{Future Work}

        \paragraph{}% 13 -- dynamic PL featues
            Dynamic programming languages typically come with performance overheads introduced by features such as dynamic typing, higher-order functions, and runtime reflection. Meta-tracing \glspl{jit} hold great potential for minimizing or even eliminating these overheads. The methods and insights presented in this dissertation could be generalized and applied to optimize a wide range of dynamic language features. While we demonstrated this approach using Racket on \emph{Pycket}, future studies might systematically explore similar optimizations in other languages and runtimes. Evaluating and adapting these techniques across diverse language implementations could lead to substantial performance improvements with relatively modest engineering effort.

        \paragraph{}% 14 -- head to head comparisonwith RacketCS across variety of programs
            Having multiple implementations of the same language or system facilitates valuable comparative research on language runtimes and compiler strategies. Our demonstration, Racket on \emph{Pycket}, alongside implementations like \emph{RacketCS}, could serve as the basis for extensive comparative studies across diverse computational patterns. Such studies could help identify complementary strengths and weaknesses of different compilation techniques, runtime architectures, and performance optimizations. Insights drawn from these comparisons could guide future research on run-time systems for dynamically-typed functional languages in general, influencing both theoretical understanding and practical development practices.

        \paragraph{}% 15 -- different ways of self-hosting
            This dissertation demonstrated self-hosting on a meta-tracing \gls{jit}, using Racket and \emph{Pycket} as a concrete implementation example. However, the general methodology could inspire further studies in various directions. For instance, future research might explore different self-hosting strategies, investigate trade-offs associated with varying abstraction levels, or systematically assess how different language design choices influence performance when using meta-tracing. Additionally, experimenting with other dynamic languages or diverse interpreter architectures could further refine our understanding of self-hosting dynamics, enabling more systematic approaches for rapid and efficient language implementation.

        \paragraph{}% 16 -- avenues for meta-tracing research
            The presented study also opens interesting avenues for deeper research on meta-tracing techniques themselves. In particular, we touched upon one of the classical problems inherent in tracing \glspl{jit}: the asymmetric penalty incurred during branch-heavy computations, where the cost of occasional slowdowns can significantly outweigh frequent fast-path optimizations. Future work might investigate methods for predicting, detecting, and effectively managing these cases, including the development of adaptive tracing heuristics, and specialized hybrid evaluation strategies. Such research could lead to meta-tracing compilers that better handle data-dependent and branch-intensive workloads, improving the overall applicability and robustness of tracing-based optimization.
