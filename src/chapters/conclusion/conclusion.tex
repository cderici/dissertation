\chapter[\texorpdfstring{CONCLUSION \& FINAL THOUGHTS}
                          {8. Conclusion}]{CONCLUSION \& FINAL THOUGHTS}

    \label{chapter:conclusion}

    \begin{chaptersynopsis}[Chapter Synopsis - \emph{Chapter Content: 40\%}]
        Conclude the dissertation.

        \vspace{2em}

        Sections:
		\begin{itemize}
            \item Contributions \& Significance
			\item Related Work
			\item Future Work
		\end{itemize}
    \end{chaptersynopsis}

    \paragraph{} \textit{Thesis:}

    \textit{Efficient self-hosting of a full-scale functional language on a meta-tracing \gls{jit} compiler is achievable.}

    \begin{paragraph-here}% 1
        We detailed our reproducible research that proves our claim...
    \end{paragraph-here}

    \begin{paragraph-here}% 2
        In this chapter we provide some related work and conclude by listing concrete contributions we made towards proving our thesis. Finally we close with a discussion of broader significance and future directions for this work.
    \end{paragraph-here}

    \section[\texorpdfstring{Contributions \& Significance}{Significance}]{Contributions \& Significance}
        \begin{paragraph-here}% 3
            This study demonstrates with evidence that it is indeed possible to have a working full-scale self-hosting functional programming language on a meta-tracing JIT compiler.
        \end{paragraph-here}

        \begin{paragraph-here}% 4
            We built a useful research vehicle, namely Pycket, that can be utilized to further research into language run-times, self-hosting, meta-tracing and more. % pycket
        \end{paragraph-here}

        \begin{paragraph-here}% 5
            We provide for the first time a formalization for the operational semantics of linklets, a compilation unit that's critical in improving the communication between a compiler and a run-time, thereby improving portability of a programming language. % linklets
        \end{paragraph-here}

        \begin{paragraph-here}% 6
            We revealed and analyzed some performance problems fundamental to self-hosting on meta-tracing \glspl{jit} and argued it is solvable, proposing solution avenues clearly worth further study.  This is a significant contribution to PL research. % problems with self-hosting
        \end{paragraph-here}

        \begin{paragraph-here}% 7
            The research also reframes performance analysis of tracing \glspl{jit}: instead of only looking for hot loops to trace, identifying what to avoid tracing can unlock full potential.
        \end{paragraph-here}

        \begin{paragraph-here}% 8
            The research provides a novel way to think about computational models in language run-times. Instead of sticking to one, several different kinds of models can be combined to exploit strengths in different areas in implementing reduction semantics. % hybrid model
        \end{paragraph-here}

    \section{Related Work}
        \label{section:related-work}

        \begin{paragraph-here}% 9
            Higher-order dynamic VMs

             Dynamic VM implementations are becoming increasingly popular for their
                rapid prototyping potential, as the effort required to implement a new
                VM from scratch is often quite large. Therefore, instead of manually
                implementing a VM in a low-level language such as C, it is often
                argued that building on top of an existing object-oriented
                general-purpose VMs or dynamic integration via generating a VM using a
                "specification" of a language allows easier and more maintainable
                implementations with competitive performance
                \cite{bolzHowNotWrite}. One of the major actors for the former approach
                is the \emph{GraalVM}, which is a modified version of the Java HotSpot
                VM on the JVM (Java Virtual Machine). GraalVM uses a language
                implementation framework called Truffle, and a method-based JIT
                compiler called Graal to implement VMs on the JVM for dynamic
                languages such as Javascript, Ruby and Python \cite{truffle-graal}. As
                opposed to building on top of VM, the \emph{RPython} project
                introduced the idea of automatically generating a VM from a language
                specification represented as an interpreter via meta-tracing
                \cite{rpython07}. For example, as mentioned in the introduction, PyPy
                is an implementation of Python that is built on the RPython
                meta-tracing framework that generated a VM including a tracing JIT for
                Python with a better performance than the CPython itself. In addition
                to the RPython framework, there are other meta-tracing systems as
                well, such as the SPUR, a tracing JIT compiler for CIL bytecode
                \cite{millerCommonLanguageInfrastructure2003}, meta-tracing languages that are implemented
                in C\# \cite{spurJIT}.
        \end{paragraph-here}

        \begin{paragraph-here}% 10
            Tracing JIT VMs

            Like PyPy, Pycket is built on the RPython meta-tracing framework as
            well, and this study tries to identify approaches on achieving
            efficient self-hosting on Pycket running a tracing JIT. Therefore it
            would be relevant to mention here some notable tracing JIT VMs
            too. Initially introduced by the Dynamo project \cite{dynamo},
            trace-based compilation is successfully utilized by many VMs including
            some commercial VMs such as Mozilla's TraceMonkey JavaScript VM
            \cite{traceMonkey}, Adobe's Tamarin ActionScript VM \cite{tamarin}, as
            well as some research VMs such as LuaJIT \cite{LuaJITLanguageToolkit}, Converge
            \cite{converge:05}, Lambdamachine \cite{lambdamachine} and PyHaskell
            \cite{pyhaskell}.
        \end{paragraph-here}

        \begin{paragraph-here}% 11
            Optimizing VM performance in a meta-tracing context

            As we mentioned in \chapterRef{chapter:rpython}, there are a lot of dynamic
            optimizations performed by the RPython back-end that the language
            interpreter should be in sync with. There are two main approaches for
            a VM author to optimize such a system: \textbf{i)} improve the
            interpreter performance, \textbf{ii)} modify the interpreter to
            produce traces that are easier to optimize by JIT. Both of these
            approaches operate on the interpreter, therefore the improvements
            should focus on the common patterns that are specific to the language
            being interpreted. For example, along with the general JIT
            improvements such as value promotion and elidable functions, PyPy and
            Converge both focus on optimizing the objects, classes and modules
            \cite{bolz15-meta-vm}.
        \end{paragraph-here}

        \begin{paragraph-here}% 12
            Self-hosting

            Similarly, Bolz and contributors state that in general-purpose VMs,
            the compiler and the language being implemented should be semantically
            in sync to achieve a good performance \cite{bolzHowNotWrite,
            runtime-feedback:11}. As we discussed in
            \chapterRef{chapter:problem}, we study the relationship between the
            semantics of the programs common to self-hosting and the interpreter
            \& trace performance. Unfortunately, to the best of our knowledge, no
            studies of self-hosting on meta-tracing has been done so far. However,
            there are self-hosting VMs for dynamic languages, such as the Tachyon
            VM for JavaScript, which is a bootstrapping JIT compiler that is
            completely hand-coded in JavaScript and doesn't use any automatic
            generation techniques \cite{self-hosted-tachyon}. Although Tachyon is
            quite different than Pycket and bootstraps the VM itself, it uses
            control-flow graphs in SSA form as an \gls{ir}, similar to Pycket. Moreover, it uses interesting techniques that
            might prove useful for Pycket as well, such as conditional constant
            propagation via abstract interpretation \cite{sccp:91}. Additionally,
            there are low-level techniques to deal with control-flow issues on VMs
            caused by large amount of branches, such as indirect branch prediction
            \cite{branch-predict:03}, which might be adapted to be useful in
            tracing as well. However, in our case implementing such techniques
            would require modifying the underlying RPython framework, where our
            approach is at the language (interpreter) level.
        \end{paragraph-here}

        \begin{paragraph-here}% 13
            Managing abstraction levels

            A big part of the problems we tackle in this thesis is caused by the
            fact that adding self-hosting on Pycket adds another level of
            abstraction that needs to be semantically in-sync with the run-time
            meta-tracing VM. There has been related research studying to reduce
            complexity in systems involving multiple levels of abstractions, such
            as type-directed partial evaluation \cite{tdpe:99} and multi-stage
            programming \cite{multi-stage:17}. Amin and Rompf studied how to
            collapse a tower of interpreters interpreting each-other into a
            compiler to remove the interpretation overhead
            \cite{collapse:17}. They developed a multi-level lambda calculus and a
            meta-circular evaluator, namely Pink, to demonstrate the collapse of
            arbitrarily many levels of self-interpretation.

            Another work that is relevant to our investigation is optimizing
            hierarchically layered VMs using trace compilation, researched by
            Yermolovich and contributors \cite{layering:09}. Similar to the
            RPython framework, they propose to run a guest VM (Lua VM
            \cite{LuaJITLanguageToolkit}) on top of a host VM with a trace-based JIT compiler
            (Tamarin \cite{tamarin}). Along with optimizing the guest VM, the host
            VM also allows the guest VM to provide hints about its interpreter
            loop that can specify which parts of the guest VM should not be traced
            for its own, thereby taking into account the guest VMs workload as
            well.

            Futamura projections maybe?
        \end{paragraph-here}

        \begin{paragraph-here}% 14
            Space concerns \& heap allocated continuations

            Many studies investigate the space complexity and optimizations aiming
            to increase performance. Some use \emph{repurposed} JIT compilers
            (RJIT) to benefit from the optimizations that the dynamic languages
            enable, such simplification of control-flow graphs
            \cite{dynStatComp:12} and run-time type feedbacks \cite{stJITdyn:12}
            in the context of adding support for dynamic languages to an existing
            static-language VMs. Others use higher-level techniques such as
            hidden-classes in Pycket \cite{pycketmain2}, similar to the maps
            introduced by Self \cite{self-maps:89} and used by PyPy
            \cite{runtime-feedback:11}.

            As we discussed in the performance section, one of the big concerns we
            identified in self-hosting is the garbage collection overhead caused
            by the long-chains of heap allocated continuations. Allocating
            activation records on the heap is studied extensively in the context
            of compiling with \cite{comp-cont:92} or without
            \cite{comp-without-cont:17} continuations \cite{whatever:19}. With
            that said, perhaps the most relevant work to our investigation with
            the stackful and CEK interpreters working together is by Hieb and
            contributors \cite{cont-heap-stack:90}, where they provide an approach
            to allocate activation records on the stack that doesn't require the
            stack to be copied when a continuation is created, thereby
            establishing an upper bound on the amount of copying which is
            otherwise unbounded. They also provide techniques for stack
            overflow/underflow recovery, which is isomorphic to continuation
            creation and re-instantiation.

            To the best of our knowledge, no comprehensive synthesis of issues and
            opportunities of self-hosting on a meta-tracing VM has been
            done. Therefore a head-to-head comparison of Pycket with such a system
            is impossible. However, existing Racket implementations such as
            Racket's previous (generic JIT-based) and current (Chez
            \cite{icfp2019}) run-time are suitable for performance
            comparison with Pycket implementing Racket.
        \end{paragraph-here}

    \section[\texorpdfstring{Future Work}{Future Work}]{Future Work}

        \begin{paragraph-here}% 15
            There are a lot of dynamic features of programming languages, overhead of which can be eliminated by meta-tracing, such as eliminating gradual typing performance with using Pycket \cite{pycketmain2}. If all the issues of self-hosting on meta-tracing JITs are solved and the full potential of our approach is realized, then a featureful language like Racket and all languages that can be built on Racket can be made extremely fast with minimal effort.
        \end{paragraph-here}

        \begin{paragraph-here}% 16
            Having another Racket implementation symmetric to RacketCS enables further research on language runtimes for functional programming languages across a variety of different types of computations. Strenghts and weaknesses of each can be identified and the whole research about VMs for dynamic languages can be improved.
        \end{paragraph-here}

        \begin{paragraph-here}% 17
            This is an example of self-hosting with on a meta-tracing \gls{jit}, and it paves the way for future work on different ways of self-hosting languages.
        \end{paragraph-here}

        \begin{paragraph-here}% 18
            It opens interesting avenues for meta-tracing research, where we also touch one of the most classical problems with tracing \glspl{jit}; you lose more when slow than you gain when fast in evaluating branch-heavy computations.
        \end{paragraph-here}
